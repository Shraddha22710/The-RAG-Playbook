{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìù Basic RAG Demo\n",
        "\n",
        "This notebook demonstrates:\n",
        "- Loading sample documents\n",
        "- Building embeddings with SentenceTransformers\n",
        "- Storing & retrieving with FAISS\n",
        "- Comparing plain LLM vs RAG responses\n"
      ],
      "metadata": {
        "id": "e5QxQLmnss1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers faiss-cpu openai\n"
      ],
      "metadata": {
        "id": "btKDObRnstJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "docs = [\n",
        "    open(\"data/documents/invoice1.txt\").read(),\n",
        "    open(\"data/documents/contract1.txt\").read(),\n",
        "    open(\"data/documents/kyc1.txt\").read(),\n",
        "]\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(docs)\n",
        "\n",
        "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "index.add(embeddings.astype(\"float32\"))\n"
      ],
      "metadata": {
        "id": "ce5csiTJszCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does the contract say about GDPR?\"\n",
        "q_emb = model.encode([query])\n",
        "\n",
        "scores, idx = index.search(q_emb.astype(\"float32\"), k=2)\n",
        "for i, j in enumerate(idx[0]):\n",
        "    print(f\"Doc {j} ‚Üí {docs[j][:200]}\")\n"
      ],
      "metadata": {
        "id": "sNcovspXszdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÇÔ∏è Chunking Strategies for RAG\n",
        "We test:\n",
        "- Fixed size\n",
        "- Overlapping\n",
        "- Semantic (sentence-based)\n"
      ],
      "metadata": {
        "id": "SRQ0qWeZs5M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = open(\"data/documents/contract1.txt\").read()\n",
        "\n",
        "def fixed_chunk(text, size=50):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
        "\n",
        "def overlap_chunk(text, size=50, overlap=10):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i+size]) for i in range(0, len(words-overlap), size-overlap)]\n",
        "\n",
        "def semantic_chunk(text, max_len=200):\n",
        "    sentences = re.split(r'[.!?]', text)\n",
        "    chunks, cur = [], \"\"\n",
        "    for s in sentences:\n",
        "        if len(cur) + len(s) > max_len:\n",
        "            chunks.append(cur.strip())\n",
        "            cur = s\n",
        "        else:\n",
        "            cur += \" \" + s\n",
        "    if cur: chunks.append(cur)\n",
        "    return chunks\n",
        "\n",
        "print(\"Fixed:\", fixed_chunk(text, 40)[:2])\n",
        "print(\"Semantic:\", semantic_chunk(text)[:2])\n"
      ],
      "metadata": {
        "id": "oexuqB0Xs7IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîç FAISS Retrieval Demo\n",
        "Explore FAISS similarity search:\n",
        "- Index docs\n",
        "- Run query\n",
        "- Show Recall@k\n"
      ],
      "metadata": {
        "id": "yIv6aySqs-xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "docs = [open(f\"data/documents/{f}\").read() for f in [\"invoice1.txt\",\"contract1.txt\",\"kyc1.txt\"]]\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(docs)\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings.astype(\"float32\"))\n",
        "\n",
        "query = \"Which document talks about payment terms?\"\n",
        "q_emb = model.encode([query])\n",
        "scores, idx = index.search(q_emb.astype(\"float32\"), 2)\n",
        "\n",
        "print(\"Top results:\", [docs[i][:120] for i in idx[0]])\n"
      ],
      "metadata": {
        "id": "BGlReiIGtAD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Multi-Agent RAG Demo\n",
        "We simulate:\n",
        "- Document Agent ‚Üí parses fields\n",
        "- Regulation Agent ‚Üí retrieves matching rules\n",
        "- Governance Agent ‚Üí validates & explains\n"
      ],
      "metadata": {
        "id": "tIISqkURtCgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentAgent:\n",
        "    def extract(self, text):\n",
        "        return {\"has_gdpr\": \"GDPR\" in text, \"length\": len(text)}\n",
        "\n",
        "class RegulationAgent:\n",
        "    def fetch_rules(self, query):\n",
        "        if \"GDPR\" in query:\n",
        "            return \"GDPR requires explicit consent for data transfers.\"\n",
        "        return \"No match.\"\n",
        "\n",
        "class GovernanceAgent:\n",
        "    def validate(self, doc, rules):\n",
        "        if doc[\"has_gdpr\"]:\n",
        "            return f\"Doc mentions GDPR ‚Üí {rules}\"\n",
        "        return \"No regulatory match.\"\n",
        "\n",
        "doc_text = open(\"data/documents/contract1.txt\").read()\n",
        "doc_agent, reg_agent, gov_agent = DocumentAgent(), RegulationAgent(), GovernanceAgent()\n",
        "\n",
        "doc_info = doc_agent.extract(doc_text)\n",
        "rules = reg_agent.fetch_rules(\"GDPR check\")\n",
        "result = gov_agent.validate(doc_info, rules)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "YzGI3grTtDz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Advanced RAG Patterns\n",
        "We try:\n",
        "- Multi-hop retrieval\n",
        "- Multimodal (text + image placeholders)\n",
        "- Adaptive retrieval\n"
      ],
      "metadata": {
        "id": "wsB1KDmitFv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Refine query\n",
        "query = \"Does the invoice mention deadlines for payment?\"\n",
        "refined = \"What is the payment due date in the invoice?\"\n",
        "\n",
        "# Step 2: Retrieve\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "docs = [open(\"data/documents/invoice1.txt\").read()]\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "emb = model.encode(docs)\n",
        "index = faiss.IndexFlatIP(emb.shape[1])\n",
        "index.add(emb.astype(\"float32\"))\n",
        "\n",
        "q_emb = model.encode([refined])\n",
        "_, idx = index.search(q_emb.astype(\"float32\"), 1)\n",
        "print(\"Multi-hop Answer:\", docs[idx[0][0]])\n"
      ],
      "metadata": {
        "id": "TjCdm3B8tH85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëâ Multimodal RAG requires combining **text embeddings** + **image embeddings** (e.g., CLIP).  \n",
        "For now, this notebook sets up placeholders for extending text RAG into multimodal pipelines.\n"
      ],
      "metadata": {
        "id": "m5JshRm3tQof"
      }
    }
  ]
}